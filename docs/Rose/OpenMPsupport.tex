\chapter{OpenMP Support}
\label{chap::ompsupport}

%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Introduction}
ROSE supports the OpenMP 3.0 specifications~\cite{OpenMP3.0}. 
OpenMP is a popular shared-memory parallel programming model which extends serial programming languages like C/C++ and Fortran 77/90 to include additional parallel semantics. 
The extensions OpenMP provides contain compiler directives, user level runtime routines and environment variables. 
Depending on the languages (C/C++ or Fortran 77-2003), the OpenMP support in ROSE
includes parsing OpenMP directive, generating dedicated AST nodes for them,
and finally translating OpenMP programs into multithreaded programs
targeting the GCC GOMP OpenMP runtime library or the Omni OpenMP runtime
library. 
We also have an implementation of automatic parallelization using OpenMP,
which automatically introduces OpenMP directives into sequential C/C++ applications.

%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Command Line Options}
Like most other OpenMP implementations, ROSE's OpenMP support has to be explicitly turned on via command line options.
By running any ROSE-based translator (e.g. identityTranslator) with \textit{-help}, 
the OpenMP-related command line options can be displayed as follows: 
{\scriptsize
\begin{verbatim}
  -rose:OpenMP, -rose:openmp
                          follow OpenMP 3.0 specification for C/C++ and Fortran, perform one of the following actions:
  -rose:OpenMP:parse_only, -rose:openmp:parse_only
                          parse OpenMP directives to OmpAttributes, no further actions (default behavior now)
  -rose:OpenMP:ast_only, -rose:openmp:ast_only
                          on top of -rose:openmp:parse_only, build OpenMP AST nodes from OmpAttributes, no further actions
  -rose:OpenMP:lowering, -rose:openmp:lowering
                          on top of -rose:openmp:ast_only, transform AST with OpenMP nodes into multithreaded code 
                          targeting GCC GOMP runtime library
\end{verbatim}
}

The options above work with any ROSE-based translators. The OpenMP support
is optionally invoked inside of \lstinline{SgProject * frontend()}. The AST
generated by \lstinline{frontend()} will reflect changes caused by OpenMP parsing and lowering depending
on the option used.
%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Entry Point and Top Level Function}
ROSE processes OpenMP directives right after preprocessing information is processed within \lstinline{SgFile::callFrontEnd()}.
This order is necessary since preprocessing information may exist within
OpenMP directives, such as macro calls.
%or named constants defined using \lstinline{#define}.
ROSE needs to be aware of such preprocessing information when processing OpenMP.

The top level function for processing OpenMP is named
\lstinline{processOpenMP()} (defined in
\textit{rose/src/frontend/ompAstConstruction.cpp}), as shown below:
\lstset{language=C,basicstyle=\scriptsize,numbers=left}
\begin{lstlisting}
void processOpenMP(SgSourceFile *sageFilePtr)
{
  ROSE_ASSERT(sageFilePtr != NULL);
  // skip if no OpenMP directives
  if (sageFilePtr->get_openmp() == false)
    return;

  // parse OpenMP directives and attach OmpAttributeList to relevant SgNode
  attachOmpAttributeInfo(sageFilePtr);

  // stop here if only OpenMP parsing is requested
  if (sageFilePtr->get_openmp_parse_only())
    return;

  //Build OpenMP AST nodes based on parsing results
  build_OpenMP_AST(sageFilePtr);

  // Stop here if only OpenMP AST construction is requested
  if (sageFilePtr->get_openmp_ast_only())
    return;

  // Translate to multithreaded code targeting GOMP
  lower_omp(sageFilePtr);
}
\end{lstlisting}
\lstset{language=C,basicstyle=\small}

%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Parsing OpenMP Directives}
Since the EDG C/C++ frontend (as of version 4.0 and earlier versions) does not support OpenMP, 
ROSE has its own OpenMP directive parsers. 
The parsers recognize all OpenMP directives as defined in OpenMP 3.0.
The source files of the OpenMP directive parser for C/C++ are located in \textit{rose/src/frontend/SageIII/ }.
They include \textit{omplexer.ll} (for Lex) and \textit{ompparser.yy} (for Yacc).
The Fortran OpenMP parser is hand crafted and has only one source file, \textit{src/frontend/SageIII/ompFortranParser.C}. 

Persistent AST attributes (\emph{OmpAttribute} as defined in
\textit{src/frontend/SageIII/OmpAttribute.h}) are generated as the results
of parsing.
The attributes are attached to relevant AST nodes and serve as a light-weight representation for OpenMP directives
since they only incur minimum changes to existing ROSE AST.
% and can be handy in some special occasions. 

A set of C/C++/Fortran OpenMP tests is located in \textit{src/tests/CompileTests/OpenMP\_tests} to test the ROSE OpenMP parsers.
%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Generating AST with OpenMP Nodes}
This phase converts the ROSE AST annotated with OmpAttribute instances into
AST with OpenMP-specific nodes.
The introduction of OpenMP-specific ROSE AST nodes can help reuse all
existing ROSE AST traversal, query, and other manipulation interfaces, thus
facilitating analysis and translation of OpenMP programs.

All OpenMP AST nodes have names starting with \textit{SgOmp}. 
Directives are treated as statement-like nodes, which in turn can have a list of clause nodes.
A list of some example OpenMP constructs and their corresponding ROSE AST nodes are given below:

{\scriptsize
\begin{verbatim}
omp atomic              SgOmpAtomicStatement
omp barrier             SgOmpBarrierStatement
omp critical            SgOmpCriticalStatement
omp parallel            SgOmpParallelStatement
omp for                 SgOmpForStatement
omp task                SgOmpTaskStatement
omp sections            SgOmpSectionsStatement
omp flush               SgOmpFlushStatement
omp taskwait            SgOmpTaskwaitStatement
omp threadprivate       SgOmpThreadprivateStatement

reduction               SgOmpReductionClause
schedule                SgOmpScheduleClause
private                 SgOmpPrivateClause
firstprivate            SgOmpFirstprivateClause
lastprivate             SgOmpLastprivateClause
nowait                  SgOmpNowaitClause
copyin                  SgOmpCopyinClause
collapse                SgOmpCollapseClause
untied                  SgOmpUntiedClause
ordered                 SgOmpOrderedClause

input                   SgOmpInputClause
output                  SgOmpOutputClause
inout                   SgOmpInoutClause
\end{verbatim}
}
 
Please refer to the ROSE Web Reference\footnote{\url{http://www.rosecompiler.org/ROSE_HTML_Reference/index.html}} for details about these nodes and their class hierarchy. 

More details about the implementation: the conversion was first implemented
for C/C++ to translate pragmas annotated with OmpAttribute to
OpenMP-specific AST nodes. We later on added implementation for Fortran. 
But Fortran does not have the concept of pragmas. In order to reuse the conversion
code we developed for C/C++, we temporarily generate pragma nodes from
Fortran OpenMP directive first and then call the conversion function (as shown below). 
\lstset{language=C,basicstyle=\scriptsize,numbers=left}
\begin{lstlisting}
  void build_OpenMP_AST(SgSourceFile *sageFilePtr)
  {
    if (is_Fortran_language())
    {
      convert_Fortran_OMP_Comments_to_Pragmas (sageFilePtr);
    }
    convert_OpenMP_pragma_to_AST( sageFilePtr);
  }

\end{lstlisting}
\lstset{language=C,basicstyle=\small}


%-------------------------------------------------------------
%-------------------------------------------------------------
\section{Translating OpenMP Directives}
Using a command line like \textit{identityTranslator -rose:openmp:lower inputcode.c},
ROSE can translate OpenMP 3.0 programs into multithreaded code targeting the XOMP runtime library. 
%\footnote{The translation supports C and C++ best. Fortran 77 is also partially supported.}.
XOMP is a thin layer of runtime which is designed to accommodate minor differences among popular OpenMP runtime libraries, such as the GCC GOMP OpenMP runtime library and the Omni OpenMP compiler runtime library. 
The motivation is to enable ROSE to support more than one runtime libraries, with minimum changes at the XOMP layer if all possible. 
More details about the design and implementation of XOMP can be found in a paper~\cite{LiaoXOMP2010}.

If the path to the underlying runtime, such as GOMP (preferably the one shipped with GCC 4.3 or above for OpenMP task support), is specified (using a configure option \textit{--with-gomp\_omp\_runtime\_library=/nfs/apps/gcc/4.4.1/lib64/}),
the generated multithreaded code can be automatically linked to the specified library to generate final executables after compilation. 

The major source file of the OpenMP translation is \textit{src/midend/ompLowering/omp\_lowering.cpp}. 
Basically, it applies the following algorithm to each input source file using OpenMP:
\begin{enumerate}
\item  Use a top-down AST traversal to make implicit data-sharing attribute explicit, including implicit private variables for loop constructs and implicit firstprivate variables for task constructs. 
\item  Uses a bottom-up AST traversal to locate OpenMP nodes and performance necessary translation for each type of them.
\begin{enumerate}
\item Handle OpenMP-specific variables, such as private, firstprivate, lastprivate and reduction variables used by the target construct, if any.
\item For parallel (\lstinline{omp parallel}) and task (\lstinline{omp task}) constructs, call the general-purpose source-to-source AST outliner~\cite{LiaoEffective2009} to generate tasks and replace the original code block with GOMP runtime calls.
\item For loop constructs, normalize target loops and generate code to
calculate iteration chunks for each thread.
\item Translation for other constructs are relatively simpler cases and
details are omitted here.
\end{enumerate}
\end{enumerate}

Many translation tests (from
\textit{ROSE\_SOURCE\_TREE/src/tests/CompileTests/OpenMP tests}) are
provided within the ROSE release, you can type
\textit{make check} under
\textit{ROSE\_BUILD\_TREE/tests/roseTests/ompLoweringTests} to see the
OpenMP translation in action.

%-------------------------------------------------------------
\subsection{Variable Handling}
The separation of OpenMP variable handling from the rest of translation is
the key to the successful reuse of a general-purpose outliner within an OpenMP 3.0 implementation. 
After OpenMP variable handling, a structured code block of a parallel or task construct becomes much easier to be handled by the outliner.

Variable handling is implemented in \lstinline{OmpSupport::transOmpVariables()}. 
It translates most OpenMP clauses with variable lists, such as private, firstprivate, lastprivate, reduction, etc.
(The threadprivate clause is not handled here and will be explained later.)
Assume \lstinline{bb} is a structured block affected by the variable clauses, the algorithm for handling OpenMP variables is given below:
\begin{enumerate}
\item Collect all variables used in clauses with variable lists
\item For each variable, do the following:
\begin{enumerate}
\item Prepend a local declaration statement for the variable to the beginning of \lstinline{bb}.
\item Insert an assignment statement after the declaration statement to initialize the local copy (e.g. for firstprivate and reduction variables).
\item Replace all references to the variable within \lstinline{bb} with references to its local copy.
\item Append an assignment statement to save the value of the local copy to its global counter part (e.g. for reduction and lastprivate variables)
\end{enumerate}
\end{enumerate}
Please note that a variable can be associated with more than one clauses, such as firstprivate and lastprivate. 


%-------------------------------------------------------------
\subsection{Parallel Regions}

Translation of a simple OpenMP parallel region 
(\lstinline{#pragma omp parallel}) without any variable uses is demonstrated in
Figure~\ref{Manual:omp:hello1-trans} for an input code shown in
Figure~\ref{Manual:omp:hello1}.

\lstset{language=C,basicstyle=\scriptsize}
\lstset{language=C,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/hello-1.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/hello-1.c}
    \end{htmlonly}
  }
}
\caption{Example of a simple parallel region}
\label{Manual:omp:hello1}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_hello-1.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_hello-1.c}
    \end{htmlonly}
  }
}
\caption{Translation of a simple parallel region}
\label{Manual:omp:hello1-trans}
\end{figure}

Similarly, translation of a simple Fortran OpenMP parallel region 
is demonstrated in
Figure~\ref{Manual:omp:hello1-trans-f} for an input code shown in
Figure~\ref{Manual:omp:hello1-f}.

\lstset{language=Fortran,basicstyle=\scriptsize}
\lstset{language=Fortran,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/helloworld.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/helloworld.f}
    \end{htmlonly}
  }
}
\caption{Example of a simple parallel region in Fortran}
\label{Manual:omp:hello1-f}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/fortran/rose_helloworld.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_helloworld.f}
    \end{htmlonly}
  }
}
\caption{Translation of a simple parallel region in Fortran}
\label{Manual:omp:hello1-trans-f}
\end{figure}


%---------------------------------------


Translation of a relatively complex OpenMP parallel region with variable references is demonstrated in
Figure~\ref{Manual:omp:preduction-trans} for an input code shown in
Figure~\ref{Manual:omp:preduction}. 
Note the handling of shared, and reduction variables during the translation.

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/parallel-reduction.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/parallel-reduction.c}
    \end{htmlonly}
  }
}
\caption{Example of a complex parallel region}
\label{Manual:omp:preduction}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_parallel-reduction.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_parallel-reduction.c}
    \end{htmlonly}
  }
}
\caption{Translation of a complex parallel region}
\label{Manual:omp:preduction-trans}
\end{figure}

Similarly, translation of a Fortran OpenMP parallel region with shared and private variables
is demonstrated in
Figure~\ref{Manual:omp:shared-trans-f} for an input code shown in
Figure~\ref{Manual:omp:shared-f}.

\lstset{language=Fortran,basicstyle=\scriptsize}
\lstset{language=Fortran,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/shared.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/shared.f}
    \end{htmlonly}
  }
}
\caption{Example of a parallel region with private and shared variables in Fortran}
\label{Manual:omp:shared-f}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/fortran/rose_shared.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_shared.f}
    \end{htmlonly}
  }
}
\caption{Translation of a parallel region with variable accesses in Fortran}
\label{Manual:omp:shared-trans-f}
\end{figure}


\clearpage
Translation of an OpenMP parallel region within a C++ class member function is demonstrated in
Figure~\ref{Manual:omp:classMember-trans} for an input code shown in
Figure~\ref{Manual:omp:classMember}. 
Note the generation of an outlined function using C-bindings and the
declaration as a friend function within the original class. 

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/memberFunction.cpp}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/memberFunction.cpp}
    \end{htmlonly}
  }
}
\caption{Example of a parallel region within a class member function}
\label{Manual:omp:classMember}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_memberFunction.cpp}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_memberFunction.cpp}
    \end{htmlonly}
  }
}
\caption{Translation of a parallel region within a class member function}
\label{Manual:omp:classMember-trans}
\end{figure}


%-------------------------------------------------------------
\clearpage
\subsection{Loop Constructs}
Translation of a loop construct is given in
Figure~\ref{Manual:omp:ompfor-trans} for an input code shown in
Figure~\ref{Manual:omp:ompfor}. 
Note that GOMP does not provide a runtime function to calculate iteration chunks for the default schedule policy. 
Compilers usually have to generate code to calculate the chunks for each thread if they directly target GOMP. 
We provide a runtime function in the XOMP runtime layer to simplify the translation. 
%We use constant folding to simplify some expressions with constant values. 

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/ompfor.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/ompfor.c}
    \end{htmlonly}
  }
}
\caption{Example of a loop construct}
\label{Manual:omp:ompfor}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompfor.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompfor.c}
    \end{htmlonly}
  }
}
\caption{Translation of a loop construct}
\label{Manual:omp:ompfor-trans}
\end{figure}

\clearpage
Similarly, translation of a Fortran OpenMP DO loop 
is demonstrated in
Figure~\ref{Manual:omp:do-default-trans-f} for an input code shown in
Figure~\ref{Manual:omp:do-default-f}.

\lstset{language=Fortran,basicstyle=\scriptsize}
\lstset{language=Fortran,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/ompdo-default.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/ompdo-default.f}
    \end{htmlonly}
  }
}
\caption{Example of a Fortran Do Loop}
\label{Manual:omp:do-default-f}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/fortran/rose_ompdo-default.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompdo-default.f}
    \end{htmlonly}
  }
}
\caption{Translation of a Fortran Do Loop}
\label{Manual:omp:do-default-trans-f}
\end{figure}


%==========
A loop with a decremental iteration space is shown in 
Figure~\ref{Manual:omp:ompfor5-trans} for an input code given in
Figure~\ref{Manual:omp:ompfor5}. 

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/ompfor5.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/ompfor5.c}
    \end{htmlonly}
  }
}
\caption{Example of an OpenMP loop with a decremental iteration space}
\label{Manual:omp:ompfor5}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompfor5.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompfor5.c}
    \end{htmlonly}
  }
}
\caption{Translation of the loop with a decremental iteration space}
\label{Manual:omp:ompfor5-trans}
\end{figure}

XOMP wraps loop scheduling functions from GOMP/Omni for loop constructs with readily
known chunk sizes (no calculation is needed) or with an ordered clause. 
Figure~\ref{Manual:omp:ompfor4-trans} shows the translation of a dynamic scheduled loop,  for an input code given in
Figure~\ref{Manual:omp:ompfor4}. 

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/ompfor4.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/ompfor4.c}
    \end{htmlonly}
  }
}
\caption{Example of an OpenMP loop with a dynamic schedule}
\label{Manual:omp:ompfor4}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompfor4.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompfor4.c}
    \end{htmlonly}
  }
}
\caption{Translation of the loop with a dynamic schedule}
\label{Manual:omp:ompfor4-trans}
\end{figure}

\clearpage
Finally, translation of multiple Fortran OpenMP DO loop 
is demonstrated in
Figure~\ref{Manual:omp:do-multiple-trans-f} for an input code shown in
Figure~\ref{Manual:omp:do-multiple-f}. Note that translation-generated loop variables
have to be grouped together in the beginning of the Fortran subroutine body, which is not necessary for 
C or C++.

\lstset{language=Fortran,basicstyle=\scriptsize}
\lstset{language=Fortran,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/ompdo-multiple.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/ompdo-multiple.f}
    \end{htmlonly}
  }
}
\caption{Example of Multiple Fortran Do Loops}
\label{Manual:omp:do-multiple-f}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/fortran/rose_ompdo-multiple.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_ompdo-multiple.f}
    \end{htmlonly}
  }
}
\caption{Translation of Multiple Fortran Do Loops}
\label{Manual:omp:do-multiple-trans-f}
\end{figure}


%-------------------------------------------------------------
\clearpage
\subsection{Threadprivate}
GCC uses thread local storage (TLS) to implement OpenMP threadprivate variables. 
No additional support is needed from the runtime library's point of view. 
The translation is very simple: add the keyword \lstinline{__thread} in front of the original declaration for a variable declared as threadprivate and then remove the OpenMP pragma. 

Figure~\ref{Manual:omp:threadprivate-trans} shows the translation result for a test input code (Figure~\ref{Manual:omp:threadprivate}). It also demonstrates the handling of loop constructs using the ordered clause.

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/threadprivate.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/threadprivate.c}
    \end{htmlonly}
  }
}
\caption{Example using threadprivate}
\label{Manual:omp:threadprivate}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_threadprivate.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_threadprivate.c}
    \end{htmlonly}
  }
}
\caption{Translation of threadprivate}
\label{Manual:omp:threadprivate-trans}
\end{figure}


%-------------------------------------------------------------
\clearpage
\subsection{Task Constructs}
The translation of task constructs is similar to the translation of parallel constructs. 
They share the same ROSE AST outliner to generate outlined functions for
explicit or implicit tasks.

Figure~\ref{Manual:omp:task_untied3-trans} shows the translation of untied task constructs(input code given in
Figure~\ref{Manual:omp:task_untied3}). 

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/task_untied3.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/task_untied3.c}
    \end{htmlonly}
  }
}
\caption{Example of untied tasks}
\label{Manual:omp:task_untied3}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_task_untied3.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_task_untied3.c}
    \end{htmlonly}
  }
}
\caption{Translation of the untied tasks}
\label{Manual:omp:task_untied3-trans}
\end{figure}

Figure~\ref{Manual:omp:task_wait-trans} shows the translation of task constructs used with taskwait( an input code given in
Figure~\ref{Manual:omp:task_wait}). 

\lstset{language=C,basicstyle=\scriptsize}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/task_wait.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/task_wait.c}
    \end{htmlonly}
  }
}
\caption{Example of tasks with taskwait}
\label{Manual:omp:task_wait}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_task_wait.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_task_wait.c}
    \end{htmlonly}
  }
}
\caption{Translation of the taskwait example}
\label{Manual:omp:task_wait-trans}
\end{figure}

\clearpage
Finally, translation of Fortran OpenMP tasks
is demonstrated in
Figure~\ref{Manual:omp:task-trans-f} for an input code shown in
Figure~\ref{Manual:omp:task-f}. 

\lstset{language=Fortran,basicstyle=\scriptsize}
\lstset{language=Fortran,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/task_largenumber.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/tests/CompileTests/OpenMP_tests/fortran/task_largenumber.f}
    \end{htmlonly}
  }
}
\caption{Example of Fortran OpenMP Tasks}
\label{Manual:omp:task-f}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/tests/roseTests/ompLoweringTests/fortran/rose_task_largenumber.f}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/tests/roseTests/ompLoweringTests/rose_task_largenumber.f}
    \end{htmlonly}
  }
}
\caption{Translation of Fortran OpenMP Tasks}
\label{Manual:omp:task-trans-f}
\end{figure}


%-------------------------------------------------------------
%-------------------------------------------------------------
\clearpage
\section{Automatic Parallelization}
ROSE has an implementation of automatic parallelization using OpenMP.
The implementation is also being used to explore semantics-aware automatic parallelization, as
described in one of our paper~\cite{LiaoExtending2009}.
Out goal is to handle both traditional C/Fortran and modern C++
applications.

As part of an ongoing and evolving work, the automatic parallelization
implementation (referred to as the ROSE parallelizer) is not yet integrated into the main
source tree of ROSE. 
The source files are currently located in
\textit{rose/projects/autoParallelization}.
A standalone executable program (named \textit{autoPar}) is generated and
installed to the installation tree of ROSE (under \textit{ROSE\_INS/bin}). 
The program will take in sequential C (or some C++) code and automatically
insert OpenMP pragmas into it, if possible. 
%-------------------------------------------------------------
\subsection{Algorithm}
The ROSE parallelizer is designed to handle both conventional loops operating on primitive
arrays and modern applications using high-level abstractions.
The parallelizer uses the following algorithm:
The loops may contain variables of either primitive data types
or STL container types, or both. 
\begin{enumerate}
  \item Preparation and Preprocessing
  \begin{enumerate}
  \item  Read a specification file for known abstractions and semantics. %to represent known abstractions and  semantics.
%  \item  Traverse AST and build a loop hierarchy.
  \item  Apply optional custom transformations based on input code semantics,
  such as converting tree traversals to loop iterations on memory
  pools.
  \item  Normalize loops, including those using iterators.
  \item  Find candidate array computation loops
  with canonical forms (for \lstinline{omp for}) or loops and functions
  operating on individual elements (for \lstinline{omp task}).
%  \item  Select eligible loops based on used operation types and  computation requirements.
  \end{enumerate}
  \item  For each candidate:
  \begin{enumerate}
    \item Skip the target if there are function calls without known semantics or side effects. %if there is not enough work, 
    \item Call dependence analysis and liveness analysis.
  % including scalars and arrays of both primitive types and STL types.
    \item Classify OpenMP variables (autoscoping), recognize references
    to the current element, and find order-independent write accesses.
    \item Eliminate dependencies associated with autoscoped variables,
    those involving only the current elements, and output dependencies
    caused by order-independent write accesses.
    \item Insert the corresponding OpenMP constructs if no dependencies
    remain.
  \end{enumerate}
\end{enumerate}
The key idea of the algorithm is to capture dependencies within a target and eliminate them later on as much as possible based on
various rules.
Parallelization is safe if there are no remaining dependencies.
Please refer to one of our papers~\cite{LiaoExtending2009} for the details. 
%-------------------------------------------------------------
\subsection{Dependence Analysis}
Dependence analysis is the basis for the parallelizer to decide whether a loop is
parallelizable.
The ROSE parallelizer invokes the dependence analysis from the loop optimizer, which implements algorithms proposed in~%
\cite{YAK:PLDI00,YK:LACSI02} to effectively transform
both perfectly nested loops and non-perfectly nested loops.
An extended direction matrix
(EDM) dependence representation is used to cover non-common loop nests that surround
only one of the two statements in order to handle non-perfectly
nested loops. For array accesses within loops, a Gaussian elimination
algorithm is used to solve a set of linear integer equations of loop induction
variables. 

Figure~\ref{code.depGraph} gives an example dependence graph dump for an input
code, in which a statement is surrounded by two loops
($\mathit{commonlevel} = 2$). 
Two true dependence relations exist, caused by two pairs of array
references and carried in both loop levels ($\mathit{CarryLevel} = 0$ and
$\mathit{CarryLevel} = 1$).  
%So the code cannot be parallelized. 
The extended direction matrices give the
dependence directions(one of $=$, $\leq$,$\geq$, and $*$) and alignment factors.
The details of the dependence analysis and corresponding graph
can be found in \cite{YAK:PLDI00,YK:LACSI02}.
%can be found in \cite{YiTransforming2004,YiTransforming2002}.
It is clear from the dependence analysis that the example code in Fig.~%
\ref{code.depGraph} cannot be parallelized because of 
loop-carried dependences in both loop levels.

% providing an example
\begin{figure}[!ht]
 \centering
%  \figure{%
        \lstinputlisting{bothlevel.c}
%  }
  \caption{\label{code.depGraph} An example output of ROSE's dependence graph}
\end{figure}


%-------------------------------------------------------------
\subsection{Variable Classification}
Table~\ref{tab:varClassification} shows the categories of
data-sharing attributes for variables based on their live-in (before the
execution of a loop) and live-out (after the execution of a loop)
analysis results. For instance, a private variable inside a
loop is neither live-in nor live-out of the loop, which means the 
variable is immediately killed (redefined) inside the loop and then used inside
the loop somehow, but is never going to be used anywhere after the loop.
All loop index variables are also classified as OpenMP private variables to a avoid
possible race condition.
On the other hand, shared variables are live at both the beginning and the end of the loop.
\lstinline{Firstprivate} and \lstinline{lastprivate} variables are live at either only the beginning or
only the end of the loop, respectively.

\begin{table}[htbp]
%\fixme{Do captions need to end with periods?} No 
\caption{OpenMP variable classification based on liveness analysis}
        \centering
\begin{tabular}{||l||c|c|c||} \hline
\textbf{Data-sharing attribute} & \textbf{Live-in} & \textbf{Live-out} &
\textbf{Written} \\ \hline
% {\bfseries\scriptsize{shared}} & Yes & Yes  & No\\ \hline
{\bfseries\scriptsize{private}} & No & No & Yes       \\ \hline
{\bfseries\scriptsize{firstprivate}} & Yes & No & No \\ \hline
{\bfseries\scriptsize{lastprivate}} & No & Yes  & Yes  \\ \hline
\end{tabular} 
% LNCS requires table captions to put at the top!!!
%\caption{Variable classification based on liveness analysis}
\label{tab:varClassification}
\end{table}

Reduction variables are handled specially to maximize the opportunities for
parallelization.
%Liveness analysis does not apply
%to them because all possible combinations for live-in and live-out on the loop can happen. 
A typical reduction operation inside a loop, such as
\lstinline{sum = sum + a[i]},
causes a loop-carried output
dependence, a loop-carried anti-dependence, and a loop independent anti-dependence.
We use an idiom recognition analysis to capture such typical operations and exclude
the associated loop-carried dependences when deciding if a loop is
parallelizable.
%-------------------------------------------------------------
\subsection{Examples}
Test input codes of the ROSE parallelizer are located in \textit{src/rojects/autoParallelization/tests}.
We show a few representative examples here. 

Figure~\ref{Manual:autopar:doall_2-trans} shows the auto parallelization result generated from  an input code given in
Figure~\ref{Manual:autopar:doall_2}).
As we can see, the ROSE parallelizer detects all parallelizable loop levels and make private loop index variables explicit.
It also reports the parallelized loops and their line numbers during the execution (shown in Figure~\ref{Manual:autopar:doall_2-output}).

\lstset{language=C,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/projects/autoParallelization/tests/doall_2.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/projects/autoParallelization/tests/doall_2.c}
    \end{htmlonly}
  }
}
\caption{Example of a simple loop}
\label{Manual:autopar:doall_2}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/projects/autoParallelization/tests/rose_doall_2.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/projects/autoParallelization/tests/rose_doall_2.c}
    \end{htmlonly}
  }
}
\caption{Parallelized code}
\label{Manual:autopar:doall_2-trans}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/projects/autoParallelization/tests/doall_2.out}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/projects/autoParallelization/tests/doall_2.out}
    \end{htmlonly}
  }
}
\caption{Screen output during the execution of the ROSE parallelizer}
\label{Manual:autopar:doall_2-output}
\end{figure}


Figure~\ref{Manual:autopar:inner_only-trans} shows the auto parallelization result generated from  an input code given in
Figure~\ref{Manual:autopar:inner_only}).
Again, the relevant information is reported during the execution (shown in Figure~\ref{Manual:autopar:inner_only-output}).
Reasons are given for loops which cannot be automatically parallelized. 

\lstset{language=C,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/projects/autoParallelization/tests/inner_only.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/projects/autoParallelization/tests/inner_only.c}
    \end{htmlonly}
  }
}
\caption{Example of a simple loop}
\label{Manual:autopar:inner_only}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/projects/autoParallelization/tests/rose_inner_only.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/projects/autoParallelization/tests/rose_inner_only.c}
    \end{htmlonly}
  }
}
\caption{Parallelized code}
\label{Manual:autopar:inner_only-trans}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/projects/autoParallelization/tests/inner_only.out}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/projects/autoParallelization/tests/inner_only.out}
    \end{htmlonly}
  }
}
\caption{Screen output during the execution of the ROSE parallelizer}
\label{Manual:autopar:inner_only-output}
\end{figure}

Reduction recognition is demonstrated in Figure~\ref{Manual:autopar:reduction-trans} generated from  an input code given in
Figure~\ref{Manual:autopar:reduction}).
The ROSE parallelizer is able to recognize reduction variables based on the
idiom recognition analysis.

\lstset{language=C,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/projects/autoParallelization/tests/reduction.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/projects/autoParallelization/tests/reduction.c}
    \end{htmlonly}
  }
}
\caption{Example of a simple loop}
\label{Manual:autopar:reduction}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/projects/autoParallelization/tests/rose_reduction.c}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/projects/autoParallelization/tests/rose_reduction.c}
    \end{htmlonly}
  }
}
\caption{Parallelized code}
\label{Manual:autopar:reduction-trans}
\end{figure}

With known semantics of STL vectors, loops operating on vectors can also be parallelized( shown in Figure~\ref{Manual:autopar:doall_vector2-trans} generated from  an input code given in Figure~\ref{Manual:autopar:doall_vector2}).

\lstset{language=C,basicstyle=\scriptsize,numbers=left}
\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopSourceDirectory/projects/autoParallelization/tests/doall_vector2.C}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopSourceDirectory/projects/autoParallelization/tests/doall_vector2.C}
    \end{htmlonly}
  }
}
\caption{Example of a simple loop operating on a vector}
\label{Manual:autopar:doall_vector2}
\end{figure}

\begin{figure}[htbp]
{\indent
  {\mySmallFontSize
    \begin{latexonly}
    \lstinputlisting{\TopBuildDirectory/projects/autoParallelization/tests/rose_doall_vector2.C}
    \end{latexonly}
    \begin{htmlonly}
    \verbatiminput{\TopBuildDirectory/projects/autoParallelization/tests/rose_doall_vector2.C}
    \end{htmlonly}
  }
}
\caption{Parallelized code}
\label{Manual:autopar:doall_vector2-trans}
\end{figure}

\subsection{More Instructions}
An executable file \textit{autoPar} is created during the process of
building ROSE.  Users can use it to parallelize their codes.
\textit{autoPar} will be installed to the path specified by
\textit{--prefix=ROSE\_INSTALLATION\_PATH}. 
%You can use \textit{autoPar} to generate an OpenMP version of your sequential code if your code is parallelizable.  
Here are some instructions.

During configuration, you might want to specify a prefix path, such as
\textit{--prefix=/home/youraccount/opt/rose-rev-8345}.
Then, follow the ROSE installation guide to build and install ROSE,
often by typing \textit{make} and \textit{make install}. 

The next step is to set environment variables for search paths for ROSE executables (including
\textit{autoPar}) and shared libraries. Assume you are using bash, put the
following lines into a file (e.g. set.rose) and source it (typing
\textit{source set.rose})

\begin{verbatim}
ROSE_INS=/home/youraccount/opt/rose-rev-8345
export ROSE_INS
PATH=$ROSE_INS/bin:$PATH
export PATH
LD_LIBRARY_PATH=$ROSE_INS/lib:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH
\end{verbatim}

Now you can use \textit{autoPar} to parallelize your code. 
Assume you have a sequential file: \textit{file.c}, 
just type \textit{autoPar -c file.c}.
An output file \textit{rose\_file.c} will be generated. 
If \textit{autoPar} can find anything parallelizable, the output file should have OpenMP pragmas generated. 

%-------------------------------------------------------------
%-------------------------------------------------------------
%\clearpage
%\section{Appendix}
%\subsection{Old OpenMP 2.0 Implementation}
%
%\subsection{Investigating GCC's OpenMP translation}
